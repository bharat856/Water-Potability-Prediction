{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cbe4bbf-55d0-4da6-ac05-1e71d203ff35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the folder path containing CSV files:  /Users/bharat_puri/Documents/AquaAware/Copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Found 2 CSV files.\n",
      "\n",
      "Columns in '/Users/bharat_puri/Documents/AquaAware/Copy/Manganese.csv': ['GEMS.Station.Number', 'Sample.Date', 'Sample.Time', 'Depth', 'Parameter.Code', 'Analysis.Method.Code', 'Value.Flags', 'Value', 'Unit', 'Data.Quality']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select columns to keep (comma-separated):  GEMS.Station.Number, Value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available columns for merging: ['GEMS.Station.Number', 'Value']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the column name to merge on:  GEMS.Station.Number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns in '/Users/bharat_puri/Documents/AquaAware/Copy/Carbon.csv': ['GEMS.Station.Number', 'Sample.Date', 'Sample.Time', 'Depth', 'Parameter.Code', 'Analysis.Method.Code', 'Value.Flags', 'Value', 'Unit', 'Data.Quality']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select columns to keep (comma-separated):  GEMS.Station.Number, Value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Merged CSV saved as '/Users/bharat_puri/Documents/AquaAware/Copy/merged_output.csv' (Merged on 'GEMS.Station.Number')\n",
      "\n",
      "✅ Correlation matrix saved as '/Users/bharat_puri/Documents/AquaAware/Copy/merged_output_correlation_matrix.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def list_csv_files(folder_path):\n",
    "    return [f for f in os.listdir(folder_path) if f.endswith('.csv') and f != \"merged_output.csv\"]\n",
    "\n",
    "def process_and_merge_csv(file_path, selected_columns, output_df, merge_column):\n",
    "    try:\n",
    "        filename = os.path.splitext(os.path.basename(file_path))[0]  \n",
    "        \n",
    "        # Read file\n",
    "        chunk = pd.read_csv(file_path, encoding=\"utf-8\", encoding_errors=\"replace\", sep=\";\", dtype=str)\n",
    "        chunk.columns = [col.strip() for col in chunk.columns]  \n",
    "        chunk = chunk[selected_columns]  \n",
    "        \n",
    "        # Rename columns (except merge column)\n",
    "        chunk = chunk.rename(columns={col: f\"{filename}_{col}\" for col in selected_columns if col != merge_column})\n",
    "        \n",
    "        # Merge with existing data\n",
    "        if output_df is None:\n",
    "            output_df = chunk\n",
    "        else:\n",
    "            output_df = pd.merge(output_df, chunk, on=merge_column, how=\"outer\")  # Merge on common column\n",
    "            \n",
    "        return output_df\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error processing '{file_path}': {e}\")\n",
    "        return output_df\n",
    "\n",
    "def get_column_selection(file_path):\n",
    "    try:\n",
    "        sample_df = pd.read_csv(file_path, encoding=\"utf-8\", encoding_errors=\"replace\", sep=\";\", dtype=str, nrows=100)\n",
    "        sample_df.columns = [col.strip() for col in sample_df.columns]\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error reading sample rows from '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nColumns in '{file_path}': {list(sample_df.columns)}\")\n",
    "    \n",
    "    while True:\n",
    "        selected = input(\"Select columns to keep (comma-separated): \").split(',')\n",
    "        selected = [col.strip() for col in selected]\n",
    "\n",
    "        invalid_columns = [col for col in selected if col not in sample_df.columns]\n",
    "        if invalid_columns:\n",
    "            print(f\"\\n⚠️ These columns do not exist in '{file_path}': {invalid_columns}. Please enter valid column names.\")\n",
    "        else:\n",
    "            break \n",
    "\n",
    "    return selected\n",
    "\n",
    "def merge_large_csvs(folder_path, csv_files, output_file):\n",
    "    global merge_column\n",
    "    merge_column = None\n",
    "    merged_df = None  \n",
    "\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        selected_columns = get_column_selection(file_path)\n",
    "        if selected_columns is None:\n",
    "            continue\n",
    "\n",
    "        if merge_column is None:\n",
    "            print(f\"\\nAvailable columns for merging: {selected_columns}\")\n",
    "            while True:\n",
    "                merge_column = input(\"\\nEnter the column name to merge on: \").strip()\n",
    "                if merge_column in selected_columns:\n",
    "                    break\n",
    "                print(f\"\\n⚠️ '{merge_column}' not found in selected columns. Please enter a valid column name.\")\n",
    "\n",
    "        # Ensure merge column is included\n",
    "        if merge_column not in selected_columns:\n",
    "            selected_columns.insert(0, merge_column)\n",
    "\n",
    "        # Process and merge data\n",
    "        merged_df = process_and_merge_csv(file_path, selected_columns, merged_df, merge_column)\n",
    "\n",
    "    # Save merged data to CSV\n",
    "    if merged_df is not None:\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "    return merge_column\n",
    "\n",
    "def generate_correlation_matrix(output_file):\n",
    "    \"\"\"Generate a correlation matrix for numerical columns.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(output_file, encoding=\"utf-8\", encoding_errors=\"replace\", dtype=str)\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')  \n",
    "        correlation_matrix = df.corr()\n",
    "        \n",
    "        correlation_output_file = output_file.replace(\".csv\", \"_correlation_matrix.csv\")\n",
    "        correlation_matrix.to_csv(correlation_output_file)\n",
    "        print(f\"\\n✅ Correlation matrix saved as '{correlation_output_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error generating correlation matrix: {e}\")\n",
    "\n",
    "def main():\n",
    "    folder_path = input(\"Enter the folder path containing CSV files: \").strip()\n",
    "    csv_files = list_csv_files(folder_path)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"⚠️ No CSV files found in the specified folder.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n✅ Found {len(csv_files)} CSV files.\")\n",
    "\n",
    "    output_file = os.path.join(folder_path, \"merged_output.csv\")\n",
    "    \n",
    "    # Remove old output file if exists\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "\n",
    "    merge_column = merge_large_csvs(folder_path, csv_files, output_file)\n",
    "\n",
    "    if merge_column is not None:\n",
    "        print(f\"\\n✅ Merged CSV saved as '{output_file}' (Merged on '{merge_column}')\")\n",
    "        generate_correlation_matrix(output_file)\n",
    "    else:\n",
    "        print(\"\\n❌ Merging failed. No output file generated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164d59ae-6194-443c-9e52-98395a0782fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  GEMS.Station.Number  Manganese_Value  Carbon_Value\n",
      "0            ARG00014            0.007          5.28\n",
      "1            ARG00014            0.224          5.28\n",
      "2            ARG00014            0.002          5.28\n",
      "3            ARG00014            1.920          5.28\n",
      "4            ARG00014            0.043          5.28\n",
      "5            ARG00014            0.563          5.28\n",
      "6            ARG00014            0.006          5.28\n",
      "7            ARG00014            0.213          5.28\n",
      "8            ARG00014            0.006          5.28\n",
      "9            ARG00014            3.925          5.28\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_path = \"/Users/bharat_puri/Documents/AquaAware/Copy/merged_output.csv\"\n",
    "\n",
    "# Read only the first 10 rows\n",
    "df = pd.read_csv(file_path, nrows=10)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292aa07-b157-47be-a2f3-30b88fcb5128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
